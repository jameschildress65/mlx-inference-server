#!/bin/bash
#
# MLX Inference Server - Smart Installation Script
# Handles fresh installs, upgrades, and cleanup
#

set -e  # Exit on any error

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

# Track what we've done for rollback
CREATED_VENV=false
CREATED_VENV_VISION=false
STARTED_SERVER=false

# Cleanup function for errors
cleanup_on_error() {
    echo ""
    echo -e "${RED}Installation failed! Rolling back changes...${NC}"

    if [ "$STARTED_SERVER" = true ]; then
        echo "  â†’ Stopping server..."
        ./bin/mlx-inference-server-daemon.sh stop 2>/dev/null || true
    fi

    if [ "$CREATED_VENV" = true ]; then
        echo "  â†’ Removing incomplete main venv..."
        rm -rf venv
    fi

    if [ "$CREATED_VENV_VISION" = true ]; then
        echo "  â†’ Removing incomplete vision venv..."
        rm -rf venv-vision
    fi

    echo -e "${RED}Rollback complete. Please check the error above and try again.${NC}"
    exit 1
}

trap cleanup_on_error ERR

# Header
echo ""
echo -e "${BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${BLUE}â•‘        MLX Inference Server - Smart Installer              â•‘${NC}"
echo -e "${BLUE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# Check prerequisites
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 1: Checking Prerequisites${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

# Check macOS
if [[ "$OSTYPE" != "darwin"* ]]; then
    echo -e "${RED}âœ— ERROR: This requires macOS (detected: $OSTYPE)${NC}"
    exit 1
fi
echo -e "${GREEN}âœ“ Operating System: macOS${NC}"

# Check Python
if ! command -v python3 &> /dev/null; then
    echo -e "${RED}âœ— ERROR: python3 not found${NC}"
    echo "  Install with: brew install python@3.12"
    exit 1
fi
PYTHON_VERSION=$(python3 --version 2>&1 | awk '{print $2}')
echo -e "${GREEN}âœ“ Python: $PYTHON_VERSION${NC}"

# Check Apple Silicon
CHIP=$(system_profiler SPHardwareDataType | grep "Chip:" | awk '{print $2, $3}')
if [[ ! "$CHIP" =~ "Apple" ]]; then
    echo -e "${RED}âœ— ERROR: Apple Silicon required (M1/M2/M3/M4)${NC}"
    echo "  Detected: $CHIP"
    exit 1
fi
echo -e "${GREEN}âœ“ Chip: $CHIP${NC}"

# Check RAM
RAM=$(system_profiler SPHardwareDataType | grep "Memory:" | awk '{print $2, $3}')
RAM_GB=$(echo "$RAM" | awk '{print $1}')
if [ "$RAM_GB" -lt 16 ]; then
    echo -e "${YELLOW}âš  Warning: ${RAM} detected (16GB+ recommended)${NC}"
else
    echo -e "${GREEN}âœ“ RAM: $RAM${NC}"
fi

echo ""

# Configure model cache location (HF_HOME)
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 2: Configure Model Storage${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

echo ""
echo "Models can be large (4-20GB each). Where should they be stored?"
echo ""

# Check if HF_HOME is already set
if [ -n "$HF_HOME" ]; then
    echo -e "${GREEN}âœ“ HF_HOME already set: $HF_HOME${NC}"
    echo ""
    echo "  ${GREEN}1)${NC} Keep current setting"
    echo "  ${YELLOW}2)${NC} Change to different location"
    echo ""
    read -p "Enter choice [1-2]: " hf_choice

    if [ "$hf_choice" = "2" ]; then
        HF_HOME=""  # Reset to trigger new selection
    fi
fi

if [ -z "$HF_HOME" ]; then
    DEFAULT_CACHE="$HOME/.cache/huggingface"

    echo "  ${GREEN}1)${NC} Default: $DEFAULT_CACHE (Recommended)"
    echo "  ${YELLOW}2)${NC} Custom location (external drive, etc.)"
    echo ""
    read -p "Enter choice [1-2]: " hf_choice

    case $hf_choice in
        1)
            HF_HOME="$DEFAULT_CACHE"
            echo -e "${GREEN}â†’ Using default: $HF_HOME${NC}"
            ;;
        2)
            echo ""
            read -p "Enter full path for model storage: " custom_path
            # Expand ~ if used
            custom_path="${custom_path/#\~/$HOME}"

            # Validate path exists or can be created
            if [ -d "$custom_path" ]; then
                HF_HOME="$custom_path"
                echo -e "${GREEN}â†’ Using: $HF_HOME${NC}"
            else
                echo "  Directory doesn't exist. Create it? [y/n]: "
                read create_dir
                if [ "$create_dir" = "y" ] || [ "$create_dir" = "Y" ]; then
                    mkdir -p "$custom_path"
                    HF_HOME="$custom_path"
                    echo -e "${GREEN}â†’ Created and using: $HF_HOME${NC}"
                else
                    echo -e "${YELLOW}â†’ Using default instead: $DEFAULT_CACHE${NC}"
                    HF_HOME="$DEFAULT_CACHE"
                fi
            fi
            ;;
        *)
            HF_HOME="$DEFAULT_CACHE"
            echo -e "${GREEN}â†’ Using default: $HF_HOME${NC}"
            ;;
    esac
fi

# Ensure HF_HOME directory exists
mkdir -p "$HF_HOME"

# Export for this session
export HF_HOME="$HF_HOME"

# Check if already in shell config
SHELL_CONFIG="$HOME/.zshrc"
if grep -q "export HF_HOME=" "$SHELL_CONFIG" 2>/dev/null; then
    echo -e "${GREEN}âœ“ HF_HOME already in $SHELL_CONFIG${NC}"
else
    echo ""
    echo "Add HF_HOME to your shell config for future sessions? [y/n]: "
    read add_to_shell
    if [ "$add_to_shell" = "y" ] || [ "$add_to_shell" = "Y" ]; then
        echo "" >> "$SHELL_CONFIG"
        echo "# MLX Inference Server - Model cache location" >> "$SHELL_CONFIG"
        echo "export HF_HOME=\"$HF_HOME\"" >> "$SHELL_CONFIG"
        echo -e "${GREEN}âœ“ Added to $SHELL_CONFIG${NC}"
    fi
fi

echo ""

# Select starter model
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 3: Download Starter Model${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

echo ""
echo "Download a model now? (Can also download later on first use)"
echo ""
echo "  ${GREEN}1)${NC} Qwen2.5-3B-Instruct-4bit (~1.9GB, fast download, good for testing)"
echo "  ${YELLOW}2)${NC} Qwen2.5-7B-Instruct-4bit (~4.1GB, recommended for regular use)"
echo "  ${BLUE}3)${NC} Skip (download on first use)"
echo ""
read -p "Enter choice [1-3]: " model_choice

DOWNLOAD_MODEL=""
case $model_choice in
    1)
        DOWNLOAD_MODEL="mlx-community/Qwen2.5-3B-Instruct-4bit"
        echo -e "${GREEN}â†’ Will download 3B model${NC}"
        ;;
    2)
        DOWNLOAD_MODEL="mlx-community/Qwen2.5-7B-Instruct-4bit"
        echo -e "${GREEN}â†’ Will download 7B model${NC}"
        ;;
    3|*)
        echo -e "${BLUE}â†’ Skipping model download${NC}"
        ;;
esac

# Download model if selected (before venv setup so user sees progress)
if [ -n "$DOWNLOAD_MODEL" ]; then
    echo ""
    echo "  â†’ Downloading $DOWNLOAD_MODEL..."
    echo "  â†’ This may take a few minutes depending on your connection"
    echo ""

    # Use huggingface-cli if available, otherwise will download on first use
    if command -v huggingface-cli &> /dev/null; then
        huggingface-cli download "$DOWNLOAD_MODEL" --quiet
        echo -e "${GREEN}  âœ“ Model downloaded to $HF_HOME${NC}"
    else
        # Will install huggingface-hub in venv later, download then
        echo -e "${YELLOW}  â†’ huggingface-cli not found, will download after venv setup${NC}"
        DOWNLOAD_AFTER_VENV=true
    fi
fi

echo ""

# Check current installation status
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 4: Checking Current Installation${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

SERVER_RUNNING=false
VENV_EXISTS=false
VENV_VISION_EXISTS=false

# Check if server is running
if pgrep -f "mlx-inference-server" > /dev/null; then
    SERVER_PID=$(pgrep -f "mlx-inference-server")
    echo -e "${YELLOW}âš  Server is currently running (PID: $SERVER_PID)${NC}"
    SERVER_RUNNING=true
else
    echo -e "${GREEN}âœ“ No server currently running${NC}"
fi

# Check if venvs exist
if [ -d "venv" ]; then
    VENV_SIZE=$(du -sh venv 2>/dev/null | awk '{print $1}')
    echo -e "${YELLOW}âš  Main venv exists ($VENV_SIZE)${NC}"
    VENV_EXISTS=true
else
    echo -e "${GREEN}âœ“ No main venv found${NC}"
fi

if [ -d "venv-vision" ]; then
    VENV_VISION_SIZE=$(du -sh venv-vision 2>/dev/null | awk '{print $1}')
    echo -e "${YELLOW}âš  Vision venv exists ($VENV_VISION_SIZE)${NC}"
    VENV_VISION_EXISTS=true
else
    echo -e "${GREEN}âœ“ No vision venv found${NC}"
fi

echo ""

# Determine installation mode
INSTALL_MODE=""

if [ "$SERVER_RUNNING" = true ] || [ "$VENV_EXISTS" = true ] || [ "$VENV_VISION_EXISTS" = true ]; then
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${YELLOW}Existing Installation Detected${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
    echo "Choose installation mode:"
    echo ""
    echo "  ${GREEN}1)${NC} Clean Install (remove everything and start fresh)"
    echo "  ${YELLOW}2)${NC} Upgrade (keep existing, just update dependencies)"
    echo "  ${RED}3)${NC} Cancel"
    echo ""
    read -p "Enter choice [1-3]: " choice

    case $choice in
        1)
            INSTALL_MODE="clean"
            echo -e "${GREEN}â†’ Clean install selected${NC}"
            ;;
        2)
            INSTALL_MODE="upgrade"
            echo -e "${YELLOW}â†’ Upgrade selected${NC}"
            ;;
        3)
            echo -e "${BLUE}Installation cancelled${NC}"
            exit 0
            ;;
        *)
            echo -e "${RED}Invalid choice. Exiting.${NC}"
            exit 1
            ;;
    esac
else
    INSTALL_MODE="clean"
    echo -e "${GREEN}â†’ Fresh installation (no existing components)${NC}"
fi

echo ""

# Stop server if running
if [ "$SERVER_RUNNING" = true ]; then
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${YELLOW}Step 5: Stopping Existing Server${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

    ./bin/mlx-inference-server-daemon.sh stop
    sleep 2

    # Verify stopped
    if pgrep -f "mlx-inference-server" > /dev/null; then
        echo -e "${RED}âœ— Server still running, force killing...${NC}"
        pkill -9 -f "mlx-inference-server"
        sleep 1
    fi

    echo -e "${GREEN}âœ“ Server stopped${NC}"
    echo ""
fi

# Clean install: remove venvs
if [ "$INSTALL_MODE" = "clean" ]; then
    if [ "$VENV_EXISTS" = true ] || [ "$VENV_VISION_EXISTS" = true ]; then
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo -e "${YELLOW}Step 6: Removing Old Virtual Environments${NC}"
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

        if [ "$VENV_EXISTS" = true ]; then
            echo "  â†’ Removing venv/ ($VENV_SIZE)..."
            rm -rf venv
            echo -e "${GREEN}  âœ“ Main venv removed${NC}"
        fi

        if [ "$VENV_VISION_EXISTS" = true ]; then
            echo "  â†’ Removing venv-vision/ ($VENV_VISION_SIZE)..."
            rm -rf venv-vision
            echo -e "${GREEN}  âœ“ Vision venv removed${NC}"
        fi

        echo ""
    fi
fi

# Install main venv
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 7: Setting Up Main Virtual Environment${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

if [ ! -d "venv" ] || [ "$INSTALL_MODE" = "clean" ]; then
    echo "  â†’ Creating venv..."
    python3 -m venv venv
    CREATED_VENV=true
    echo -e "${GREEN}  âœ“ Virtual environment created${NC}"
fi

source venv/bin/activate

echo "  â†’ Upgrading pip..."
pip install --upgrade pip -q

if [ "$INSTALL_MODE" = "clean" ]; then
    echo "  â†’ Installing dependencies (5-10 minutes)..."
    pip install -r requirements.txt -q
else
    echo "  â†’ Updating dependencies..."
    pip install --upgrade -r requirements.txt -q
fi

echo "  â†’ Verifying installation..."
python -c "import mlx.core as mx; print(f'    âœ“ MLX: {mx.__version__}')"
python -c "import fastapi; print('    âœ“ FastAPI')"
python -c "import posix_ipc; print('    âœ“ posix_ipc')"
python -c "from PIL import Image; print('    âœ“ Pillow')"
python -c "import fitz; print('    âœ“ PyMuPDF')"

deactivate
echo -e "${GREEN}âœ“ Main venv ready${NC}"
echo ""

# Download model if deferred from earlier
if [ "$DOWNLOAD_AFTER_VENV" = true ] && [ -n "$DOWNLOAD_MODEL" ]; then
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${YELLOW}Downloading Selected Model${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
    echo "  â†’ Downloading $DOWNLOAD_MODEL..."
    echo "  â†’ This may take a few minutes..."
    echo ""

    source venv/bin/activate
    pip install huggingface-hub -q
    huggingface-cli download "$DOWNLOAD_MODEL"
    deactivate

    echo -e "${GREEN}  âœ“ Model downloaded to $HF_HOME${NC}"
    echo ""
fi

# Install vision venv
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 8: Setting Up Vision Virtual Environment${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

if [ ! -d "venv-vision" ] || [ "$INSTALL_MODE" = "clean" ]; then
    echo "  â†’ Creating venv-vision..."
    python3 -m venv venv-vision
    CREATED_VENV_VISION=true
    echo -e "${GREEN}  âœ“ Virtual environment created${NC}"
fi

source venv-vision/bin/activate

echo "  â†’ Upgrading pip..."
pip install --upgrade pip -q

if [ "$INSTALL_MODE" = "clean" ]; then
    echo "  â†’ Installing vision dependencies (10-15 minutes)..."
    echo "  â†’ (PyTorch is large, please be patient)"
    pip install -r requirements-vision.txt -q
else
    echo "  â†’ Updating vision dependencies..."
    pip install --upgrade -r requirements-vision.txt -q
fi

echo "  â†’ Verifying installation..."
python -c "import mlx_vlm; print('    âœ“ mlx-vlm')"
python -c "from PIL import Image; print('    âœ“ Pillow')"
python -c "import torch; print('    âœ“ PyTorch')"
python -c "import torchvision; print('    âœ“ Torchvision')"

deactivate
echo -e "${GREEN}âœ“ Vision venv ready${NC}"
echo ""

# Start server
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 9: Starting Server${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

./bin/mlx-inference-server-daemon.sh start
STARTED_SERVER=true

echo "  â†’ Waiting for initialization..."
sleep 5

# Verify health
echo "  â†’ Checking health endpoints..."
MAIN_HEALTH=$(curl -s http://localhost:11440/health 2>/dev/null || echo "failed")
ADMIN_HEALTH=$(curl -s http://localhost:11441/admin/health 2>/dev/null || echo "failed")

if [[ "$MAIN_HEALTH" == *"healthy"* ]]; then
    echo -e "${GREEN}  âœ“ Main API: http://localhost:11440${NC}"
else
    echo -e "${RED}  âœ— Main API not responding${NC}"
    exit 1
fi

if [[ "$ADMIN_HEALTH" == *"healthy"* ]] || [[ "$ADMIN_HEALTH" == *"degraded"* ]]; then
    echo -e "${GREEN}  âœ“ Admin API: http://localhost:11441${NC}"
else
    echo -e "${RED}  âœ— Admin API not responding${NC}"
    exit 1
fi

echo ""

# Test text inference
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 10: Testing Text Inference${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

# Use downloaded model if available, otherwise use small 0.5B for quick test
TEST_MODEL="${DOWNLOAD_MODEL:-mlx-community/Qwen2.5-0.5B-Instruct-4bit}"
echo "  â†’ Testing with: $TEST_MODEL"
echo "  â†’ Sending test request..."
RESPONSE=$(curl -s -X POST http://localhost:11440/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d "{
    \"model\": \"$TEST_MODEL\",
    \"messages\": [{\"role\": \"user\", \"content\": \"Say hello in 3 words\"}],
    \"max_tokens\": 10
  }" 2>/dev/null)

if [[ "$RESPONSE" == *"assistant"* ]]; then
    TOKENS_PER_SEC=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['usage'].get('tokens_per_sec', 'N/A'))" 2>/dev/null || echo "N/A")
    CONTENT=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['choices'][0]['message']['content'])" 2>/dev/null || echo "")
    echo -e "${GREEN}  âœ“ Text inference working${NC}"
    echo "    Speed: $TOKENS_PER_SEC tok/s"
    echo "    Response: \"$CONTENT\""
else
    echo -e "${RED}  âœ— Text inference failed${NC}"
    exit 1
fi

echo ""

# Test ProcessRegistry (robust)
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${YELLOW}Step 11: Testing ProcessRegistry${NC}"
echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"

# Test 1: Registry initialization
echo "  â†’ Checking ProcessRegistry initialization..."
if grep -q "ProcessRegistry initialized" logs/mlx-inference-server.log; then
    echo -e "${GREEN}  âœ“ ProcessRegistry initialized${NC}"
else
    echo -e "${RED}  âœ— ProcessRegistry not initialized${NC}"
    exit 1
fi

# Test 2: Worker registration
echo "  â†’ Testing worker registration with: $TEST_MODEL"
curl -s -X POST "http://localhost:11441/admin/load?model_path=$TEST_MODEL" > /dev/null
sleep 5

if [ -f "/tmp/mlx-server/worker_registry.json" ]; then
    WORKER_COUNT=$(cat /tmp/mlx-server/worker_registry.json | python3 -c "import sys, json; print(len(json.load(sys.stdin).get('workers', {})))" 2>/dev/null || echo "0")
    if [ "$WORKER_COUNT" == "1" ]; then
        WORKER_PID=$(cat /tmp/mlx-server/worker_registry.json | python3 -c "import sys, json; w=json.load(sys.stdin).get('workers', {}); print(list(w.keys())[0] if w else '')" 2>/dev/null)
        echo -e "${GREEN}  âœ“ Worker registered (PID: $WORKER_PID)${NC}"
    else
        echo -e "${RED}  âœ— Worker registration failed${NC}"
        exit 1
    fi
else
    echo -e "${RED}  âœ— Registry file not found${NC}"
    exit 1
fi

# Test 3: Orphan cleanup (critical test)
echo "  â†’ Testing orphan cleanup (simulated crash)..."
SERVER_PID=$(cat /tmp/mlx-inference-server.pid 2>/dev/null)
WORKER_PID_BEFORE=$(cat /tmp/mlx-server/worker_registry.json | python3 -c "import sys, json; w=json.load(sys.stdin).get('workers', {}); print(list(w.keys())[0] if w else '')" 2>/dev/null)

# Simulate crash
kill -9 $SERVER_PID 2>/dev/null || true
sleep 2

# Restart
./bin/mlx-inference-server-daemon.sh start > /dev/null 2>&1
sleep 5

# Check if orphan was detected and cleaned
if grep -q "Found 1 orphaned workers" logs/mlx-inference-server.log 2>/dev/null; then
    if ! ps -p $WORKER_PID_BEFORE > /dev/null 2>&1; then
        echo -e "${GREEN}  âœ“ Orphan cleanup working (killed worker $WORKER_PID_BEFORE)${NC}"
    else
        echo -e "${YELLOW}  âš  Orphan detected but not killed${NC}"
    fi
else
    if ! ps -p $WORKER_PID_BEFORE > /dev/null 2>&1; then
        echo -e "${GREEN}  âœ“ Worker cleaned up (exited gracefully)${NC}"
    else
        echo -e "${RED}  âœ— Orphan cleanup failed - worker $WORKER_PID_BEFORE still running${NC}"
        exit 1
    fi
fi

# Verify registry is clean
FINAL_WORKER_COUNT=$(cat /tmp/mlx-server/worker_registry.json | python3 -c "import sys, json; print(len(json.load(sys.stdin).get('workers', {})))" 2>/dev/null || echo "0")
if [ "$FINAL_WORKER_COUNT" == "0" ]; then
    echo -e "${GREEN}  âœ“ Registry clean after restart${NC}"
else
    echo -e "${RED}  âœ— Registry not clean (contains $FINAL_WORKER_COUNT workers)${NC}"
    exit 1
fi

echo ""

# Success summary
echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${GREEN}â•‘       Installation Successful! (robust) âœ“             â•‘${NC}"
echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""
echo -e "${CYAN}Installation Summary:${NC}"
echo -e "  ${GREEN}âœ“${NC} Main venv installed ($(du -sh venv 2>/dev/null | awk '{print $1}'))"
echo -e "  ${GREEN}âœ“${NC} Vision venv installed ($(du -sh venv-vision 2>/dev/null | awk '{print $1}'))"
echo -e "  ${GREEN}âœ“${NC} Model cache: $HF_HOME"
if [ -n "$DOWNLOAD_MODEL" ]; then
    echo -e "  ${GREEN}âœ“${NC} Model downloaded: $DOWNLOAD_MODEL"
fi
echo -e "  ${GREEN}âœ“${NC} Server running (PID: $(pgrep -f mlx-inference-server))"
echo -e "  ${GREEN}âœ“${NC} Text inference tested ($TOKENS_PER_SEC tok/s)"
echo ""
echo -e "${CYAN}Server Endpoints:${NC}"
echo "  â€¢ Main API:  http://localhost:11440"
echo "  â€¢ Admin API: http://localhost:11441"
echo ""
echo -e "${CYAN}Management Commands:${NC}"
echo "  â€¢ Status:  ./bin/mlx-inference-server-daemon.sh status"
echo "  â€¢ Logs:    tail -f logs/mlx-inference-server.log"
echo "  â€¢ Stop:    ./bin/mlx-inference-server-daemon.sh stop"
echo "  â€¢ Restart: ./bin/mlx-inference-server-daemon.sh restart"
echo ""
echo -e "${CYAN}Next Steps:${NC}"
echo "  1. Install Open WebUI:"
echo "     ${BLUE}pip install open-webui${NC}"
echo ""
echo "  2. Start Open WebUI:"
echo "     ${BLUE}open-webui serve${NC}"
echo ""
echo "  3. Configure connection:"
echo "     Point to: ${BLUE}http://localhost:11440/v1${NC}"
echo ""
echo -e "${GREEN}Ready to use! ðŸš€${NC}"
echo ""
